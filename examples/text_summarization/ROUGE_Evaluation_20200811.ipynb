{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "## Set QUICK_RUN = True to run the notebook on a small subset of data and a smaller number of epochs.\n",
    "QUICK_RUN = True\n",
    "## Set USE_PREPROCSSED_DATA = True to skip the data preprocessing\n",
    "USE_PREPROCSSED_DATA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch\n",
    "\n",
    "nlp_path = os.path.abspath(\"../../\")\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "\n",
    "# from utils_nlp.dataset.cnndm import CNNDMBertSumProcessedData, CNNDMSummarizationDataset\n",
    "# from utils_nlp.dataset.bundesministerium import BUNDBertSumProcessedData, BUNDSummarizationDataset\n",
    "from utils_nlp.dataset.swiss import SwissSummarizationDataset\n",
    "\n",
    "from utils_nlp.eval import compute_rouge_python, compute_rouge_perl\n",
    "from utils_nlp.models.transformers.extractive_summarization import (\n",
    "    ExtractiveSummarizer,\n",
    "    ExtSumProcessedData,\n",
    "    ExtSumProcessor,\n",
    ")\n",
    "\n",
    "from utils_nlp.models.transformers.datasets import SummarizationDataset\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# things to do:\n",
    "\n",
    "# clean up old pytorch tensors somehow?\n",
    "\n",
    "# create the oracle summaries of each\n",
    "\n",
    "# create the lead_1,lead_2,lead_3 summaries of each\n",
    "\n",
    "# calculate rouge scores for BundesSet and swiss dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUNDES_PYTORCH_DATA_PATH = \"/home/ubuntu/mnt/data/bundes_dataset/bundes_processed/\"\n",
    "torch_bundes_train = torch.load(os.path.join(BUNDES_PYTORCH_DATA_PATH, \"train_full.pt\"))\n",
    "torch_bundes_test = torch.load(os.path.join(BUNDES_PYTORCH_DATA_PATH, \"test_full.pt\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(torch_bundes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src           object\n",
       "src_txt       object\n",
       "tgt           object\n",
       "tgt_txt       object\n",
       "oracle_ids    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary'] = df['tgt_txt'].apply(lambda x: x[0])\n",
    "df['source'] = df['src_txt'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_ext = os.path.abspath(\"/home/ubuntu/adaptive-extractive-summarization/notebooks/\")\n",
    "if ada_ext not in sys.path:\n",
    "    sys.path.insert(0, ada_ext)\n",
    "\n",
    "import processing_utils\n",
    "\n",
    "df['source_len'] = processing_utils.text_length(df['source'])\n",
    "df['source_word_count'] = processing_utils.word_count(df['source'])\n",
    "\n",
    "df['summary_len'] = processing_utils.text_length(df['summary'])\n",
    "df['summary_word_count'] = processing_utils.word_count(df['summary'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      WARC/1.0 WARC-Type: response WARC-Date: 2019-1...\n",
       "1      WARC/1.0 WARC-Type: response WARC-Date: 2019-0...\n",
       "2      WARC/1.0 WARC-Type: response WARC-Date: 2020-0...\n",
       "3      WARC/1.0 WARC-Type: response WARC-Date: 2019-1...\n",
       "4      WARC/1.0 WARC-Type: response WARC-Date: 2019-1...\n",
       "                             ...                        \n",
       "256    WARC/1.0 WARC-Type: response WARC-Date: 2020-0...\n",
       "257    WARC/1.0 WARC-Type: response WARC-Date: 2018-1...\n",
       "258    WARC/1.0 WARC-Type: response WARC-Date: 2020-0...\n",
       "259    Coronapandemie: Artikel der Bundeskanzlerin un...\n",
       "260    WARC/1.0 WARC-Type: response WARC-Date: 2019-0...\n",
       "Name: source, Length: 261, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df shape:  (20560, 11)\n",
      "drop summary duplicates:  (17880, 11)\n",
      "drop source duplicates:  (17139, 11)\n",
      "drop summaries that are the same as the source:  (16788, 11)\n",
      "drop summary that is large percentage of source :  (2768, 11)\n",
      "keep only sources 80 words and over:  (276, 11)\n",
      "remove summaries that end with ... (261, 11)\n",
      "remove summaries that are longer than 200 words ... (261, 11)\n"
     ]
    }
   ],
   "source": [
    "summary_ratio = 0.8\n",
    "\n",
    "print(\"Original df shape: \", df.shape)\n",
    "\n",
    "df = df.drop_duplicates(subset=['summary'])\n",
    "print(\"drop summary duplicates: \", df.shape)\n",
    "\n",
    "df = df.drop_duplicates(subset=['source'])\n",
    "print(\"drop source duplicates: \", df.shape)\n",
    "\n",
    "df = df[~(df['source'] == df['summary'])]\n",
    "print(\"drop summaries that are the same as the source: \", df.shape)\n",
    "\n",
    "df = df[df['summary'].str.len() <  df['source'].str.len()*summary_ratio]\n",
    "print(\"drop summary that is large percentage of source : \", df.shape)\n",
    "\n",
    "df = df[df['source_word_count']>=80]\n",
    "print(\"keep only sources 80 words and over: \", df.shape)\n",
    "\n",
    "df = df[~df['summary'].str.contains('...',regex=False)]\n",
    "print(\"remove summaries that end with ...\", df.shape)\n",
    "\n",
    "df = df[df['summary_word_count']<150]\n",
    "print(\"remove summaries that are longer than 200 words ...\", df.shape)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "validation = False\n",
    "\n",
    "if DATA_NAME is \"cnndm\":\n",
    "    train_dataset, test_dataset = CNNDMSummarizationDataset(top_n=TOP_N, local_cache_path=DATA_PATH)\n",
    "elif DATA_NAME is \"swiss\":\n",
    "    if validation:\n",
    "        train_dataset, validation_dataset, test_dataset = SwissSummarizationDataset(top_n=TOP_N, validation=True, language='german')\n",
    "    else:\n",
    "        train_dataset, test_dataset = SwissSummarizationDataset(top_n=TOP_N, validation=False, language='german')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(train_dataset), len(validation_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "ext_sum_train = processor.preprocess(train_dataset, oracle_mode=\"greedy\")\n",
    "ext_sum_test = processor.preprocess(test_dataset, oracle_mode=\"greedy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DATA = False\n",
    "\n",
    "\n",
    "# save and load preprocessed data\n",
    "\n",
    "if SAVE_DATA:\n",
    "    save_path = os.path.join(DATA_PATH, DATA_NAME + \"_processed\")\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    torch.save(ext_sum_train, os.path.join(save_path, \"train_full.pt\"))\n",
    "    torch.save(ext_sum_test, os.path.join(save_path, \"test_full.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ext_sum_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_sum_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ext_sum_train[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Option 2] Reuse cached preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_PREPROCSSED_DATA:\n",
    "    save_path = os.path.join(DATA_PATH)\n",
    "    ext_sum_train = torch.load(os.path.join(save_path, \"train_full.pt\"))\n",
    "    ext_sum_test = torch.load(os.path.join(save_path, \"test_full.pt\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "To start model training, we need to create a instance of ExtractiveSummarizer.\n",
    "\n",
    "Potentionally, roberta-based model and xlnet can be supported but needs to be tested.\n",
    "#### Choose the encoder algorithm.\n",
    "There are four options:\n",
    "- baseline: it used a smaller transformer model to replace the bert model and with transformer summarization layer\n",
    "- classifier: it uses pretrained BERT and fine-tune BERT with **simple logistic classification** summarization layer\n",
    "- transformer: it uses pretrained BERT and fine-tune BERT with **transformer** summarization layer\n",
    "- RNN: it uses pretrained BERT and fine-tune BERT with **LSTM** summarization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5 # batch size, unit is the number of samples\n",
    "MAX_POS_LENGTH = 512\n",
    "\n",
    "\n",
    "# GPU used for training\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "\n",
    "# Encoder name. Options are: 1. baseline, classifier, transformer, rnn.\n",
    "ENCODER = \"transformer\"\n",
    "\n",
    "# Learning rate\n",
    "LEARNING_RATE=2e-3\n",
    "\n",
    "# How often the statistics reports show up in training, unit is step.\n",
    "REPORT_EVERY=50\n",
    "\n",
    "# total number of steps for training\n",
    "MAX_STEPS=1e2\n",
    "# number of steps for warm up\n",
    "WARMUP_STEPS=5e2\n",
    "    \n",
    "if not QUICK_RUN:\n",
    "    MAX_STEPS=5e4\n",
    "    WARMUP_STEPS=5e3\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summarizer = ExtractiveSummarizer(processor, MODEL_NAME, ENCODER, MAX_POS_LENGTH, CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "\n",
    "summarizer.fit(\n",
    "            ext_sum_train,\n",
    "            num_gpus=NUM_GPUS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            gradient_accumulation_steps=2,\n",
    "            max_steps=MAX_STEPS,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            warmup_steps=WARMUP_STEPS,\n",
    "            verbose=True,\n",
    "            report_every=REPORT_EVERY,\n",
    "            clip_grad_norm=False,\n",
    "            use_preprocessed_data=False\n",
    "        )\n",
    "\n",
    "#\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer.save_model(\n",
    "    os.path.join(\n",
    "        CACHE_DIR,\n",
    "        \"extsum_modelname_{0}_usepreprocess{1}_steps_{2}.pt\".format(\n",
    "            MODEL_NAME, USE_PREPROCSSED_DATA, MAX_STEPS\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "[ROUGE](https://en.wikipedia.org/wiki/ROUGE_(metric)), or Recall-Oriented Understudy for Gisting Evaluation has been commonly used for evaluating text summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading a previous saved model\n",
    "\n",
    "model_filename = \"dist_extsum_model.pt\"\n",
    "model_filepath = \"/home/ubuntu/mnt/train/distilbert-base-german-cased/2007142250/\"\n",
    "model_path = os.path.join(model_filepath, model_filename)\n",
    "summarizer = ExtractiveSummarizer(processor, MODEL_NAME, ENCODER, MAX_POS_LENGTH, CACHE_DIR)\n",
    "summarizer.model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"segs\" in ext_sum_test[0]: # preprocessed_data\n",
    "    source = [i['src_txt'] for i in ext_sum_test]\n",
    "    target = [\"\\n\".join(i['tgt_txt'].split(\"<q>\")) for i in ext_sum_test]\n",
    "else:\n",
    "    source = []\n",
    "    temp_target = []\n",
    "    for i in ext_sum_test:\n",
    "        source.append(i[\"src_txt\"]) \n",
    "        temp_target.append(\" \".join(j) for j in i['tgt']) \n",
    "    target = [''.join(i) for i in list(temp_target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sentence_separator = \"\\n\"\n",
    "prediction = summarizer.predict(ext_sum_test, num_gpus=NUM_GPUS, batch_size=BATCH_SIZE, sentence_separator=sentence_separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scores = compute_rouge_python(cand=prediction, ref=target)\n",
    "pprint.pprint(rouge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0].replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample_results.txt','w') as f:\n",
    "    for i in range(len(prediction)):\n",
    "        source_output = \" \".join(source[i]) \n",
    "        f.write(\"Source Text: \\n\")\n",
    "        f.write(\"\\\"\" + source_output + \"\\\" \\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"Source target: \\n\")\n",
    "        f.write(\"\\\"\" + target[i] + \"\\\" \\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"Model Prediction: \\n\")\n",
    "        f.write(\"\\\"\" + prediction[i].replace(\"\\n\", \" \") + \"\\\" \\n\")        \n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"======================================\")        \n",
    "        f.write(\"\\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "sb.glue(\"rouge_2_f_score\", rouge_scores['rouge-2']['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on a single input sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"\"\"\n",
    "Italien erlaubt nach tagelangem Zögern den etwa 180 Migranten auf dem privaten Rettungsschiff \"Ocean Viking\" den Wechsel auf das italienische Quarantäne-Schiff \"Moby Zaza\". Die Übernahme der aus Seenot geretteten Menschen sei für Montag geplant, hieß es am Samstagabend aus Quellen im Innenministerium in Rom. Zuvor hatte sich die Lage auf dem Schiff der Organisation SOS Méditerranée, das sich in internationalen Gewässern vor Sizilien befindet, zugespitzt.\n",
    "Die Betreiber berichteten demnach von einem Hungerstreik unter den Geflüchteten. Verena Papke, Geschäftsführerin von SOS Méditerranée für Deutschland, hatte am Freitag von mehreren Suizidversuchen gesprochen. Die \"Ocean Viking\" hatte zudem den Notstand an Bord ausgerufen. Bis dahin waren mehrere Bitten um Zuweisung eines sicheren Hafens in Malta und Italien erfolglos geblieben.\n",
    "\n",
    "Corona-Abstriche bei den Migranten geplant\n",
    "Die Crew sandte die dringende Anfrage an die Behörden beider Länder zur Aufnahme von rund 45 Menschen, die in schlechter Verfassung seien. Italien schickte daraufhin am Samstag einen Psychiater und einen kulturellen Mediator aus Pozzallo für mehrere Stunden an Bord, berichteten beide Seiten. Danach kam die Erlaubnis aus Rom zur Übernahme auf die \"Moby Zaza\". Die Lage an Bord habe sich jedoch etwas entspannt, hieß es aus der italienischen Hauptstadt. Am Sonntag seien zunächst Corona-Abstriche bei den Migranten geplant.\n",
    "\n",
    "Wie SOS Méditerranée am Samstag schrieb, nahm das Schiff in insgesamt vier Einsätzen am 25. und am 30. Juni etwa 180 Menschen aus dem Mittelmeer an Bord. Italien und Malta hatten sich in der Corona-Pandemie zu nicht sicheren Häfen erklärt. Trotzdem brechen Migranten von Libyen und Tunesien in Richtung Europa auf. Rom und Valletta nahmen zuletzt zwar wieder Menschen von privaten Schiffen auf, doch die Länder zögern mit der Zuweisung von Häfen oft lange. Sie fordern von anderen EU-Staaten regelmäßig Zusagen über die Weiterverteilung der Menschen.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SummarizationDataset(\n",
    "    None,\n",
    "    source=[source],\n",
    "    source_preprocessing=[tokenize.sent_tokenize],\n",
    "    word_tokenize=nltk.word_tokenize,\n",
    "    language='german'\n",
    ")\n",
    "processor = ExtSumProcessor(model_name=MODEL_NAME,  cache_dir=CACHE_DIR)\n",
    "preprocessed_dataset = processor.preprocess(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = summarizer.predict(preprocessed_dataset, num_gpus=0, batch_size=1, sentence_separator=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up temporary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(DATA_PATH):\n",
    "    shutil.rmtree(DATA_PATH, ignore_errors=True)\n",
    "if os.path.exists(CACHE_DIR):\n",
    "    shutil.rmtree(CACHE_DIR, ignore_errors=True)\n",
    "if USE_PREPROCSSED_DATA:\n",
    "    if os.path.exists(PROCESSED_DATA_PATH):\n",
    "        shutil.rmtree(PROCESSED_DATA_PATH, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Environment (conda_nlp_gpu)",
   "language": "python",
   "name": "conda_nlp_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
